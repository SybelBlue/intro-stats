# Review!


## The big picture

![](https://www.macalester.edu/~ajohns24/images/stat155/schedule_1.png)

\
\


**The bigger picture**

You've learned a powerful set of foundational tools in STAT 155. These will get you far, but not everywhere. Here's where STAT 155 fits into the broader STAT curriculum:    

\


- **COMP/STAT 112: Intro to Data Science**    
    Whereas STAT 155 focuses on statistical *modeling*, STAT 112 dives more deeply into data scraping, wrangling, visualization, and interaction. Not only are these steps required before we can do any modeling, they provide a complementary lens for a more holistic analysis.

    


- **STAT 253: Statistical Machine Learning**    
    Picks up where STAT 155 leaves off, expanding upon our modeling tools for "supervised analyses" (exploring relationships between y and x) while also exploring tools for "unsupervised analyses" (when we just have a bunch of features x and no y).
    

- **Working with other data types**    
    - **STAT 452: Correlated Data**    
        Our STAT 155 models assume that the cases / rows in a dataset are *independent*. This assumption doesn't always hold!Correlated Data explores tools that apply when cases are temporally, spatially, or structurally dependent.    
        
    - **STAT 453: Survival Analysis**    
        Our STAT 155 models assume that $y$ is quantitative or categorical, but not much else.Survival Analysis explores tools that are specialized to exploring "time to event" $y$ variables.
    

- **Working through other lenses**    
    - **STAT 451: Causal Inference**    
        STAT 155 provides tools that allow us to explore *correlation* among variables. It doesn't even attempt to establish *causation*. Causal Inference addresses the big question of "when *does* correlation imply causation?".    
        
    - **STAT 155: Bayesian Statistics**    
        STAT 155 looks at statistical machine learning through a *frequentist* lens. The *Bayesian* philosophy provides an alternative lens. Mainly, we can take our 155 tools and look at them as either Bayesians or frequentists. Simply put, Bayesians formally interpret data in light of their *prior* understanding and ask different questions than frequentists (eg: no p-values!).    





\
\



**You can learn more without taking classes!**    

The following are great ways to continue playing around with data:

- [TidyTuesday](https://github.com/rfordatascience/tidytuesday) posts a new data set each week. There's a broad community that shares their analyses and ideas (#tidytuesday). [David Robinson](https://www.youtube.com/channel/UCeiiqmVK07qhY-wvg3IZiZQ/videos) often posts screencasts demonstrating how he works through the data. 
    
- [Kaggle](https://www.kaggle.com/) hosts a larger data repository and community. Since there are so many datasets, this is a bit more overwhelming than TidyTuesday (my opinion), but still fun.
    
- [Jo Hardin](https://teachdatascience.com/keepbusy/) has a great list of more ideas!




\
\
\
\





## Exercises


**Goals**    

- Bring together some big course *themes* while practicing some details. This is not an exhaustive review for Quiz 3, but is a great start.

- Self-assess and identify the areas where you're a bit rusty (thus where you might spend more time reviewing).

- You can skip around and over as you see fit for your own review purposes. There are a _lot_ of questions - this is not designed to plow through in one sitting.


\
\


**Getting started**


```{r}
# Load packages
library(ggplot2)
library(dplyr)

# Import data on flights
flights <- read.csv("https://www.macalester.edu/~ajohns24/data/flights_small.csv") %>% 
  mutate(day_of_week = as.factor(day_of_week), month = as.factor(month))
```


\
\


**Data story**    

In the exercises below, you'll be studying trends in flights leaving from three different airports: LAX (Los Angeles), MSP (Minneapolis-St Paul), and ORD (Chicago O'Hare). This is a subset of data originally posted on kaggle: https://www.kaggle.com/usdot/flight-delays#flights.csv


\
\






## Exercise 1: Open ended: Get to know the data

Before we do any modeling or analysis, take a few moments to familiarize yourself with the data. (What kinds of things are you looking at here?)
    
    
\
\



## Exercise 2: total_time vs airport: open-ended

The `total_time` variable measures the total time of a flight experience in minutes, *including* delays, time in the air, and time sitting in the plane on the ground. One point of interest is how the `total_time` of a flight (in minutes) might vary by the `airport` from which it departs, in our sample data and beyond. Take a basic first attempt at exploring this relationship. Since the whole point of this activity is to help you review, *you* get to determine how deep you want to go here. The goals here are to:    

- practice identifying which visualization, numerical summary, and modeling tools are appropriate here; and

- build your comfort level in working in the open-ended settings which are common outside the classroom environment. 
    
    
    
    
\
\



## Exercise 3: total_time vs airport: directed exploratory analysis

Let's consider the relationship between `total_time` and `airport` through some directed questions. (You might have already taken some of these steps above.)
    
a. .    
    ```{r}
    # Calculate the average total_time for each airport

    # Visualize the relationship between total_time and airport

    # Model the relationship between total_time and airport

    ```

b. Interpret each value in the estimate column.


c. On average, which airport has the longest total_time? The shortest?
    




\
\



## Exercise 4: total_time vs airport: directed inferential analysis I


a. Interpret the standard error in the `airportORD` row.


b. Using the Central Limit Theorem and information in the model summary table, sketch the sampling distribution for $\hat{\beta}_2$, possible estimates of the true `airportORD` coefficient $\beta_2$. Interpret what the sampling distribution tells us.


c. Construct and interpret a 95% CI for $\beta_2$ using the 68-95-99.7 Rule. Check your work using `confint()`.    
    
    

    

\
\



## Exercise 5: total_time vs airport: directed inferential analysis II

For the `airportORD` coefficient $\beta_2$, let's test the hypothesis that $\beta_2 < 0$.

a. In words and the context of this model, interpret the meaning of this hypothesis.    


b. Report and interpret the `t value` for this test.       


c. Report and interpret the p-value for this test.    


d. Based on this work, what conclusion do you make about the hypothesis test? Is it statistically significant? Practically significant?    


e. What type of error might you be making?    
    





\
\



## Exercise 6: total_time vs airport & distance: open-ended    

Of course, a flight's `distance` is also a factor in `total_time`. Thus in exploring how the `total_time` of a flight (in minutes) might vary by the `airport` from which it departs, we should control for this factor. Take a basic first attempt at exploring the relationship among these three variables. Again, *you* get to determine how deep you want to go here.





\
\



## Exercise 7: total_time vs airport & distance: directed exploratory analysis I

Let's consider the relationship of `total_time` with `airport` and `distance` through some directed questions. (You might have already taken some of these steps above.)

a. Visualize the relationship between total_time, airport, and distance.    


b. Model the relationship WITH an interaction term. Write out formulas of `total_time` vs `distance` for each of the 3 airports.


c. Explain what the *signs* (+ or -) of the `distance`, `airportMSP:distance`, and `airportORD:distance` coefficients indicate about the relationships of interest.


d. Notice that the interaction coefficients are statistically significant. Are they practically significant?






\
\



## Exercise 8: total_time vs airport & distance: directed inferential analysis I    

a. Model the relationship WITHOUT an interaction term. Report the model summary table.


b. Interpret the `airportORD` and `distance` coefficients.


c. Report and interpret the R-squared of this model.


d. Considering this model alongside that without a `distance` predictor, how did controlling for `distance` change / enhance our understanding of the flights leaving from ORD?


e. Bonus: explain *how* this "Simpson's Paradox" might have happened. 





\
\



## Exercise 9: total_time vs airport & distance: directed inferential analysis II


For further practice, suppose we were to test $H_0: \beta_1 = 0$ vs $H_a: \beta_1 > 0$ where $\beta_1$ is the actual `airportMSP` coefficient.    

a. Interpret the meaning of $H_0$ in this context.


b. Using the Central Limit Theorem and information in the model summary table, sketch the sampling distribution for $\hat{\beta}_1$, possible estimates of $\beta_1$ that we'd expect if $H_0$ were true. Indicate the range on the x-axis.


c. Mark our sample estimate on your sketch.


d. Use the 68-95-99.7 Rule to approximate the p-value for this test: less than 0.0015, between 0.0015 & 0.025, between 0.025 & 0.16, or greater than 0.16.
    
    




\
\



## Exercise 10: Prediction intervals

a. Your neighbor is flying out of MSP tomorrow on a 1000 mile flight. Compute a interpret a 95% prediction interval for their total flight experience.


b. Compute a interpret a 95% confidence interval for the *typical* total flight experience for all 1000 mile flights leaving from MSP.
    





\
\



    
## Exercise 11: Last question on this model

a. If we had to pick just *one* predictor, which is the better predictor of `total_time`, `airport` or `distance`?    


b. Are `airport` and `distance` multicollinear predictors? Provide some evidence, either visual or numerical.
    
        

\
\



## Exercise 12: Running late


```{r}
# Plot departure_delay (the number of minutes late or early a flight leaves)

# Define a new variable, is_late, which indicates  
# whether a flight leaves at least 15 minutes late (>= 15)

# Plot is_late

# Challenge: Calculate the observed chance of late flights on each day of the week

```
    

\
\


## Exercise 13: Modeling the chances of being late: open-ended  

So what exactly is associated with an increase risk of a flight being late? Take a basic first attempt at exploring the relationship of `is_late` with: `airport`, `distance`, `day_of_week`, `month`, and `late_night_departure` (whether the flight leaves between 10pm and 6am). Again, you get to determine how deep you want to go here.




\
\





## Exercise 14: Modeling the chances of being late: directed analysis

a. Construct a model of `is_late` by `airport`, `distance`, `day_of_week`, `month`, and `late_night_departure` (whether the flight leaves between 10pm and 6am). Report the model summary table.


b. Controlling for distance, what is the ideal airport, day of week, month, and time of day for a flight (presuming one doesn't want to be late)?


c. Suppose somebody is taking a 1000 mile flight out of MSP on a Monday afternoon (day 1) in March (month 3). What's the probability their flight will be late?
    
    
    
    
    
    
\
\



## Exercise 15: Modeling the chances of being late: last questions


a. Interpret the `distance` coefficient (not on the log scale).


b. Interpret the `airportORD` coefficient (not on the log scale).


c. Do a quick check of the p-values associated with these two predictors. Summarize your conclusions.

    
\
\




## Exercise 16: Choose your own adventure

There are a lot of other features to consider in this dataset. Explore some!



\
\
\
\


