# Confidence Intervals & the CLT



\
\



**Getting Started**    

Load the packages, data, and special functions you'll need for this activity. These special functions are designed only for this activity.

```{r message = FALSE, warning = FALSE}
# Load packages
library(dplyr)
library(ggplot2)
library(infer)
library(broom)

# Import & wrangle data
elections <- read.csv("https://www.macalester.edu/~ajohns24/data/election_2020.csv") %>% 
  mutate(per_gop_2020 = 100*per_gop_2020, 
    per_gop_2016 = 100*per_gop_2016, per_gop_2012 = 100*per_gop_2012)

# Define special functions
CI_sim <- function(level, n){    
  # Take 100 samples of size n
  samples <- rep_sample_n(elections, size = n, reps = 100, replace = FALSE)
    
  # Confidence intervals from each sample
  CIs <- samples %>%    
    group_by(replicate) %>%     
    do(tidy(
      lm(per_gop_2020 ~ per_gop_2012, data = .),
      conf.int = TRUE, conf.level = level)) %>% 
    filter(term == "per_gop_2012") %>% 
    select(replicate, conf.low, conf.high) %>% 
    rename(lower = conf.low, upper = conf.high)

  CIs %>% 
    mutate(lucky = (lower < 1.000 & upper > 1.000),
      estimate = (upper + lower) / 2)
}

CI_plot <- function(CIs){
  ggplot(CIs, aes(y = replicate, x = lower, color = lucky)) + 
    geom_segment(aes(x = lower, xend = upper, y = replicate, yend = replicate)) + 
    geom_point(aes(x = estimate, y = replicate)) + 
    lims(x = c(0.55, 1.45)) + 
    geom_vline(xintercept = 1.000)
}
```



\
\
\
\





## Discussion



---

**Remember the big picture**    

Let $\beta$ be an actual feature of a population (which is unknown) and $\hat{\beta}$ be a corresponding sample **estimate**. Then we want to know:

- What's the potential **error** in $\hat{\beta}$?    
- Taking into account $\hat{\beta}$ and its corresponding error, what's a range of plausible values for $\beta$? 

---



\
\
\
\



**EXAMPLE**    

A January 2021 [Monmouth University poll](https://www.monmouth.edu/polling-institute/documents/monmouthpoll_us_012721.pdf/) of U.S. adults reported a 51% disapproval rating for Congress with a 3.5% *margin of error* with 95% *confidence*. This both gives us a sense of the potential error in the polling estimate and a potential range for the disapproval rating among the broader public. This range is called a **95% confidence interval**: 

51 +/- 3.5 = (51 - 3.5, 51 + 3.5) = (47.5, 54.5)










\
\
\
\




**The Story**

Using election data on the full population of U.S. counties (minus Alaska), the "actual" model between the 2020 and 2012 Republican support is as follows:

$$\text{per_gop_2020} = \beta_0 + \beta_1 \text{ per_gop_2012} = 5.179 + 1.000 \text{ per_gop_2012}$$


```{r}
population_mod <- lm(per_gop_2020 ~ per_gop_2012, data = elections)
summary(population_mod)$coefficients
```

Yet, suppose we were only able to sample **n** of these counties. In the previous activity, we simulated the corresponding **sampling distributions** and **standard errors** for the slope estimates $\hat{\beta}_1$ by taking 500 different samples of size n. For example: On average, estimates of the slope as calculated from a sample of 50 counties tend to be off by 0.07.


![](https://www.macalester.edu/~ajohns24/images/stat155/samp_dist_example_new.png)




\
\
\
\





**The SNAG and our goal**

These simulated sampling distributions are merely *hypothetical*. In practice, we take only **one sample** hence can't actually obtain the sampling distribution. Instead, we must **approximate** the potential error in our sample estimates! There are two common approaches to this approximation:    

- **Central Limit Theorem (CLT)**    
    Makes theoretical assumptions about the sampling distribution and standard error

- **Bootstrapping -- OPTIONAL**    
    Uses simulation to approximate the standard error. Will typically give similar conclusions as the CLT, but is more generalizable to estimation in settings outside the 155 context.



\
\
\
\



---

**Central Limit Theorem (CLT)**


So long as our sample size n is "large enough", the **CLT** assumes that the possible sample estimates $\hat{\beta}$ are *Normally* distributed around the actual population value $\beta$ (which, in practice, *we do not know*),    
    
$$\hat{\beta} \sim N(\beta, \text{standard error}^2)$$

where the standard error is calculated from our *sample* via some complicated formula which decreases as sample size increases ($c / \sqrt{n}$). Thus by the 68-95-99.7 Rule:    

- **68%** of samples will produce $\hat{\beta}$ estimates within **1 st. err.** of $\beta$
- **95%** of samples will produce $\hat{\beta}$ estimates within **2 st. err.** of $\beta$
- **99.7%** of samples will produce $\hat{\beta}$ estimates within **3 st. err.** of $\beta$


![](https://www.macalester.edu/~ajohns24/images/CLT_68_95_997.png)


---







\
\
\
\





## Exercises



Let's **pretend** we don't have access to the full population data and, instead, can take only **one sample of 50 counties**:

```{r}
# Take a sample
set.seed(34)    
one_sample_50 <- sample_n(elections, size = 50, replace = FALSE)

# Estimate the model
one_sample_model <- lm(per_gop_2020 ~ per_gop_2012, one_sample_50)
summary(one_sample_model)$coefficients
```


**Before moving on:**    

Let $\beta_1 = 1.000$ denote the actual `per_gop_2012` coefficient and $\hat{\beta}_1 = 0.896$ denote our sample estimate of this coefficient.



\
\



## Exercise 0: Hello!

Are you planning to take a module 5 course? If so, which are you hoping to take?



\
\


## Exercise 1: Approximating standard error using CLT

Though our sampling distribution simulation provided insight into the standard error of the `per_gop_2012` coefficient estimates based on samples of 50 counties (0.07), this was merely hypothetical. In reality, we observe only 1 sample: `one_sample_50`. In this case we can use the CLT to *estimate* the standard error using only this data (and a complicated formula). In fact, this estimate is reported right in the `one_sample_model` summary table under the `Std. Error` column.    
    
a. What is the estimated standard error for the `per_gop_2012` coefficient reported in the model summary table?

0.05152905

b. How close is this CLT estimate to the actual standard error of 0.07? Does it overestimate or underestimate the potential error in our model?
```{r}
(0.07 - 0.05152905) / 0.07
```

It's a reasonable underestimate.



\
\



## Exercise 2: Applying the CLT

Based on the `one_sample_50` data alone, the CLT assumes that the *possible* sample estimates of the `per_gop_2012` coefficient ($\hat{\beta}_1$) vary from sample to sample, are Normally centered around the actual population coefficient ($\beta_1$), and have a typical error of 0.0515:
    
$$\hat{\beta}_1 \stackrel{\cdot}{\sim} N\left(\beta_1, 0.0515^2\right)$$

![](https://www.macalester.edu/~ajohns24/images/stat155/clt_example.png)
    
According to the CLT, approximately what % of samples will produce estimates $\hat{\beta}_1$ that are...

a. bigger than $\beta_1$: **50%**

b. lucky: within 2 standard errors (0.1030) of $\beta_1$: **95%**

c. unlucky: more than 2 standard errors (0.1030) from $\beta_1$: **5%**

d. really unlucky: more than 3 standard errors (0.1545) from $\beta_1$  **0.3%**   
    



\
\




## Exercise 3: Using the CLT to construct a 95% confidence interval    
Recall our sample estimate ($\hat{\beta}_1 = 0.8964$) along with its corresponding standard error (0.0515):

```{r}
summary(one_sample_model)$coefficients
```

a. CHALLENGE: Use this sample model information to calculate a "95% confidence interval", or range of plausible values, for the actual population value $\beta_1$. Hints:    
    - estimate +/- some margin of error    
    - remember the CLT with the 68-95-99.7 rule: there's a 95% chance that your sample estimate is within 2 standard errors of $\beta_1$     

``` {r}
c(11.8822173 - 3.26519505 * 2, 11.8822173 + 3.26519505 * 2)
```
b. Calculate a more accurate confidence interval in RStudio. Your interval should be close, but not exactly the same.    

```{r}
confint(one_sample_model, level = 0.95)
```    

    
    
\
\



## Exercise 4: Were we lucky?

We've seen before that some samples are lucky and some aren't.

a. How many standard errors away is *our* sample estimate $\hat{\beta}_1 = 0.896$ from the actual $\beta_1 = 1.000$? NOTE: This is a Z-score.    
```{r}
(0.896 - 1.000) / 0.0515
```
    
    
b. Did our sample produce a 95% confidence interval that contains the actual $\beta_1 = 1.000$?

No.

c. In light of a and b, is our `one_sample_50` one of the lucky samples? NOTE: If not, it's not because we did anything wrong! It's just an unlucky roll of the dice.

\[\mathbf{Nat~20!}\]

\
\


## Exercise 5: 95% confidence

The use of "95% confidence" (instead of 100% confidence) indicates that such unlucky samples are possible. But what exactly does "95% confidence" *mean*? To answer this question, let's repeat our experiment 100 times. That is, take 100 different samples of 50 counties and, from each, calculate a 95% CI for $\beta_1$:

```{r}
set.seed(1)
CI95 <- CI_sim(level = 0.95, n = 50)
head(CI95)
```

Next, visualize the 100 CIs calculated from 100 different samples. Each sample's interval is centered at its estimate $\hat{\beta}_1$, represented by a dot. Intervals that do NOT cover the true $\beta_1 = 1.000$ are highlighted in red.

```{r}
CI_plot(CI95)
```    

QUESTION: What percentage of your 100 intervals *do* cover $\beta_1$? Not coincidentally, this should be close to 95%!
95%


\
\



## Exercise 6: Impact of sample size

a. Suppose we increase our sample size from 50 to 200 counties. What does your intuition say: will the confidence intervals for $\beta_1$ be narrower or wider?    
    Narrower.

b. Check your intuition:    
```{r}
set.seed(1)
CI95new <- CI_sim(level = 0.95, n = 200)
CI_plot(CI95new)
```
  
c. Approximately what % of the CIs contain $\beta_1$?    
    97%
    
    
\
\




## Exercise 7: Impact of confidence level

Consider lowering our **confidence level** from 95% to 68% so that only 68% of samples would produce 68% CIs that cover $\beta_1$.    

a. Intuitively, if we're only 68% confident in a 68% CI, will it be narrower or wider than a 95% CI?    
Narrower.

b. If we calculate an approximate 95% CI for $\beta_1$ by $\hat{\beta}_1$ +/- 2 standard errors, how would we calculate a 68% CI?
\[\pm\sigma\]

c. Check your intuition.    
```{r}
# 68% CIs for samples of size 50
set.seed(1)
CI68 <- CI_sim(level = 0.68, n = 50)
CI_plot(CI68)
```


d. What if we wanted to be VERY confident that our CI covered $\beta_1$?  Check out 100 different 99.7% CIs for $\beta_1$:    
    
```{r}
set.seed(1)
CI997 <- CI_sim(level = 0.997, n = 50)
CI_plot(CI997)
```
    
    OR if we wanted to be **100%** confident!  Check out the CIs (RStudio can't plot these!):
    
```{r}
CI100 <- CI_sim(level = 1, n = 50)
CI100
```



\
\



## Exercise 8: Trade-offs

Summarize the trade-offs in increasing confidence levels:

a. As confidence level increases, does the percent of CIs that cover $\beta_1$ increase, decrease, or stay the same?    
Increase.

b. As confidence level increases, does the width of a CI increase, decrease, or stay the same?
Increase.

c. Why is a very wide CI less useful than a narrower CI? 
Doesn't give us a very good idea of how good our estimate is.



\
\



## Exercise 9: Traditions

Practitioners typically use a 95% confidence level when reporting estimates with an accompanying measure of error. Comment on why you think this is.

It's a decent trade off. That amount of uncertainty is acceptable, and tight data will give you good estimates.


\
\


## Exercise 10: Practice constructing CIs

Recall our `one_sample_model`:

```{r}
summary(one_sample_model)$coefficients
```

a. Approximate the 68% CI for $\beta_1$ using the CLT with the 68-95-99.7 rule.
```{r}
c(11.8822173 - 3.26519505, 11.8822173 + 3.26519505)
```

b. Similarly, approximate the 99.7% CI for $\beta_1$.
```{r}
c(11.8822173 - 3 * 3.26519505, 11.8822173 + 3 * 3.26519505)
```


c. Check your work using `confint()`.    

```{r}
confint(one_sample_model, level = 0.68)
confint(one_sample_model, level = 0.997)
```    


\
\









## Optional video

\
\

Watch this [great video](https://www.youtube.com/watch?v=jvoxEYmQHNM) to see the CLT explained using bunnies & dragons.

